<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Sphere Cam</title>
    <style>
        /* --- Reset & Base --- */
        * { box-sizing: border-box; -webkit-tap-highlight-color: transparent; }
        body { 
            margin: 0; overflow: hidden; background: #000; font-family: sans-serif; 
            touch-action: none; /* Prevent scroll on mobile */
        }

        /* --- Layers --- */
        /* 1. Video Feed (Bottom) */
        #webcam {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            object-fit: cover; z-index: 1; transform: scaleX(-1); /* Mirror effect */
        }

        /* 2. 3D Overlay (Middle) */
        #canvas-container {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 2; pointer-events: none; /* Allow touches to pass if needed, but we handle via JS */
        }

        /* 3. UI (Top) */
        #ui-layer {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
            display: flex; flex-direction: column; justify-content: space-between;
        }

        /* --- UI Elements --- */
        .status-bar {
            background: rgba(0,0,0,0.6); color: white; padding: 10px 20px;
            text-align: center; font-size: 14px; margin: 20px; border-radius: 20px;
            backdrop-filter: blur(4px); pointer-events: auto;
        }

        .center-reticle {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            width: 250px; height: 250px;
            border: 2px dashed rgba(255, 255, 255, 0.8); border-radius: 12px;
            box-shadow: 0 0 0 9999px rgba(0,0,0,0.5); /* Dim the surroundings */
        }

        .controls {
            display: flex; justify-content: center; align-items: center; gap: 20px;
            padding-bottom: 40px; pointer-events: auto; width: 100%;
        }

        /* Buttons */
        .btn-circle {
            width: 70px; height: 70px; border-radius: 50%;
            border: 4px solid white; background: rgba(0,0,0,0.3);
            position: relative; cursor: pointer; transition: transform 0.1s;
        }
        .btn-circle::after {
            content: ''; position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            width: 50px; height: 50px; background: #2ecc71; border-radius: 50%;
        }
        .btn-circle:active { transform: scale(0.9); }

        .btn-rect {
            padding: 12px 24px; background: #3498db; color: white; border: none;
            border-radius: 8px; font-weight: bold; font-size: 16px; cursor: pointer;
            box-shadow: 0 4px 6px rgba(0,0,0,0.3);
        }

        /* Intro / Start Screen */
        #start-screen {
            position: fixed; top: 0; left: 0; width: 100%; height: 100%;
            background: #111; z-index: 100;
            display: flex; flex-direction: column; justify-content: center; align-items: center;
            color: white; text-align: center; padding: 20px;
        }
        .loading-spinner {
            border: 4px solid #333; border-top: 4px solid #3498db;
            border-radius: 50%; width: 40px; height: 40px;
            animation: spin 1s linear infinite; margin-bottom: 20px;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        /* Hide elements initially */
        .hidden { display: none !important; }
    </style>
</head>
<body>

    <!-- Start / Loading Screen -->
    <div id="start-screen">
        <div class="loading-spinner" id="loader"></div>
        <h2 id="status-msg">Loading Computer Vision...</h2>
        <p style="color:#aaa; font-size: 14px;">(This downloads ~8MB, please wait)</p>
        <button id="btn-start" class="btn-rect hidden" style="margin-top:20px; font-size:20px; padding:15px 40px;">
            START CAMERA
        </button>
    </div>

    <!-- Video Feed -->
    <video id="webcam" playsinline muted autoplay></video>

    <!-- 3D Canvas -->
    <div id="canvas-container"></div>

    <!-- UI Overlay -->
    <div id="ui-layer" class="hidden">
        <div class="status-bar" id="tracker-status">Initializing Tracker...</div>
        
        <div class="center-reticle"></div>

        <div class="controls">
            <!-- Capture Button -->
            <div id="btn-capture" class="btn-circle"></div>
            <!-- Finish Button (Hidden initially) -->
            <button id="btn-finish" class="btn-rect hidden">VIEW SPHERE</button>
            <!-- Reload Button (Hidden initially) -->
            <button id="btn-restart" class="btn-rect hidden" style="background:#e74c3c">NEW</button>
        </div>
    </div>

    <!-- Libraries -->
    <!-- 1. OpenCV for Tracking -->
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onCvLoaded()"></script>
    
    <!-- 2. Three.js for 3D Sphere -->
    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';

        // --- Configuration ---
        const TRACKING_POINTS = 40;
        const MIN_POINTS = 10;
        const SENSITIVITY = 0.003; // Adjust mouse rotation speed

        // --- Globals ---
        let video, canvasContainer;
        let scene, camera, renderer, cubeMesh;
        let materials = [];
        let cvReady = false;
        let isTracking = false;
        let isViewerMode = false;
        
        // OpenCV Variables
        let cap, oldGray, frameGray, p0, p1, st, err;

        // State
        let capturedCount = 0;

        // --- DOM Elements ---
        const startScreen = document.getElementById('start-screen');
        const startBtn = document.getElementById('btn-start');
        const statusMsg = document.getElementById('status-msg');
        const uiLayer = document.getElementById('ui-layer');
        const trackerStatus = document.getElementById('tracker-status');
        const btnCapture = document.getElementById('btn-capture');
        const btnFinish = document.getElementById('btn-finish');
        const btnRestart = document.getElementById('btn-restart');

        // --- 1. Initialization ---
        
        window.onCvLoaded = function() {
            cvReady = true;
            document.getElementById('loader').style.display = 'none';
            statusMsg.innerText = "System Ready";
            startBtn.classList.remove('hidden');
        };

        startBtn.addEventListener('click', async () => {
            startBtn.innerText = "Requesting Access...";
            try {
                // Initialize Video
                video = document.getElementById('webcam');
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }, 
                    audio: false 
                });
                video.srcObject = stream;
                
                // Wait for video to actually play data
                video.onloadedmetadata = () => {
                    video.play();
                    startScreen.style.display = 'none';
                    uiLayer.classList.remove('hidden');
                    initThreeJS();
                    initTracking();
                    animate();
                };
            } catch (err) {
                alert("Camera Error: " + err.message + "\nEnsure you are on HTTPS or Localhost.");
                startBtn.innerText = "RETRY";
            }
        });

        // --- 2. Three.js Setup (The UI/Overlay) ---

        function initThreeJS() {
            canvasContainer = document.getElementById('canvas-container');
            
            // Scene Setup
            scene = new THREE.Scene();
            scene.background = null; // Transparent!

            camera = new THREE.PerspectiveCamera(90, window.innerWidth / window.innerHeight, 0.1, 100);
            camera.position.set(0, 0, 0.1); // Inside the box

            renderer = new THREE.WebGLRenderer({ alpha: true, antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(window.devicePixelRatio);
            canvasContainer.appendChild(renderer.domElement);

            // Create Cube (The "Globe" segments)
            const geo = new THREE.BoxGeometry(10, 10, 10);
            
            // Create 6 transparent materials with wireframes
            for(let i=0; i<6; i++) {
                // Create a canvas for the label "Face X"
                const lblCanvas = document.createElement('canvas');
                lblCanvas.width = 256; lblCanvas.height = 256;
                const ctx = lblCanvas.getContext('2d');
                ctx.fillStyle = 'rgba(255,255,255,0.1)';
                ctx.fillRect(0,0,256,256);
                ctx.strokeStyle = 'white';
                ctx.lineWidth = 4;
                ctx.strokeRect(0,0,256,256);
                
                const tex = new THREE.CanvasTexture(lblCanvas);
                
                const mat = new THREE.MeshBasicMaterial({ 
                    map: tex,
                    transparent: true,
                    opacity: 0.5,
                    side: THREE.BackSide
                });
                mat.userData = { filled: false, originalTex: tex };
                materials.push(mat);
            }

            cubeMesh = new THREE.Mesh(geo, materials);
            cubeMesh.scale.set(-1, 1, 1); // Invert scale for inside view
            scene.add(cubeMesh);

            // Resize Handler
            window.addEventListener('resize', () => {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            });

            // Button Listeners
            btnCapture.addEventListener('click', captureSegment);
            btnFinish.addEventListener('click', finishAndSave);
            btnRestart.addEventListener('click', () => location.reload());
        }

        // --- 3. OpenCV Tracking (The "Gyro") ---

        function initTracking() {
            // Setup Matrices
            const width = video.videoWidth;
            const height = video.videoHeight;
            
            cap = new cv.VideoCapture(video);
            oldGray = new cv.Mat(height, width, cv.CV_8UC1);
            frameGray = new cv.Mat(height, width, cv.CV_8UC1);
            p0 = new cv.Mat();
            p1 = new cv.Mat();
            st = new cv.Mat();
            err = new cv.Mat();

            // Initial Capture
            cap.read(oldGray);
            cv.cvtColor(oldGray, oldGray, cv.COLOR_RGBA2GRAY);
            
            // Find Initial Features
            detectFeatures();
            isTracking = true;
        }

        function detectFeatures() {
            // Identify corners to track
            let none = new cv.Mat();
            cv.goodFeaturesToTrack(oldGray, p0, TRACKING_POINTS, 0.3, 7, none, 3, false, 0.04);
            none.delete();
            trackerStatus.innerText = "Tracking Object...";
            trackerStatus.style.color = "#2ecc71"; // Green
        }

        function processTracking() {
            if (!isTracking || isViewerMode) return;

            try {
                // Read new frame
                cap.read(frameGray);
                cv.cvtColor(frameGray, frameGray, cv.COLOR_RGBA2GRAY);

                // If we have points, calculate flow
                if (p0.rows > 0) {
                    let winSize = new cv.Size(15, 15);
                    let maxLevel = 2;
                    let criteria = new cv.TermCriteria(cv.TermCriteria_EPS | cv.TermCriteria_COUNT, 10, 0.03);
                    
                    // Optical Flow
                    cv.calcOpticalFlowPyrLK(oldGray, frameGray, p0, p1, st, err, winSize, maxLevel, criteria);

                    // Calculate Movement
                    let dx = 0, dy = 0, count = 0;
                    
                    // Create new array of healthy points
                    let goodPoints = [];

                    for (let i = 0; i < st.rows; i++) {
                        if (st.data[i] === 1) { // 1 = Found
                            const x0 = p0.data32F[i*2];
                            const y0 = p0.data32F[i*2+1];
                            const x1 = p1.data32F[i*2];
                            const y1 = p1.data32F[i*2+1];

                            // Simple Delta
                            dx += (x1 - x0);
                            dy += (y1 - y0);
                            count++;
                            
                            // Keep point for next frame
                            goodPoints.push(x1);
                            goodPoints.push(y1);
                        }
                    }

                    // Apply to Camera (Invert Logic for "Looking Around")
                    if (count > 0) {
                        dx /= count;
                        dy /= count;
                        
                        camera.rotation.y -= dx * SENSITIVITY;
                        camera.rotation.x -= dy * SENSITIVITY;
                    }

                    // Check Object Handover
                    if (count < MIN_POINTS) {
                        trackerStatus.innerText = "Acquiring New Features...";
                        trackerStatus.style.color = "yellow";
                        detectFeatures(); // Re-scan full frame for new objects
                    } else {
                        // Update p0 with p1 data manually
                        // We recreate p0 from the good points to keep memory clean
                        p0.delete(); 
                        p0 = new cv.Mat(goodPoints.length / 2, 1, cv.CV_32FC2);
                        for(let i=0; i<goodPoints.length; i++) {
                            p0.data32F[i] = goodPoints[i];
                        }
                    }

                } else {
                    detectFeatures();
                }

                // Swap frames
                frameGray.copyTo(oldGray);

            } catch (e) {
                console.error("Tracking Error:", e);
                // Fail-safe: try to re-init if crash
                detectFeatures(); 
            }
        }

        // --- 4. Capture & Storage ---

        function captureSegment() {
            // Raycast to find which face we are facing
            const raycaster = new THREE.Raycaster();
            raycaster.setFromCamera(new THREE.Vector2(0, 0), camera);
            const intersects = raycaster.intersectObject(cubeMesh);

            if (intersects.length > 0) {
                const faceIndex = intersects[0].face.materialIndex;
                const mat = materials[faceIndex];

                // Capture high-res square from video
                const size = 1024;
                const canvas = document.createElement('canvas');
                canvas.width = size; canvas.height = size;
                const ctx = canvas.getContext('2d');

                const vW = video.videoWidth;
                const vH = video.videoHeight;
                const min = Math.min(vW, vH);
                
                // Mirror logic to match CSS mirror
                ctx.translate(size, 0);
                ctx.scale(-1, 1);
                
                // Center crop
                ctx.drawImage(video, (vW-min)/2, (vH-min)/2, min, min, 0, 0, size, size);

                // Update Texture
                if(mat.map) mat.map.dispose();
                mat.map = new THREE.CanvasTexture(canvas);
                mat.map.colorSpace = THREE.SRGBColorSpace;
                mat.opacity = 1; 
                mat.needsUpdate = true;

                // Flash Effect
                const flash = document.createElement('div');
                flash.style.cssText = "position:fixed;top:0;left:0;width:100%;height:100%;background:white;z-index:999;transition:opacity 0.2s;";
                document.body.appendChild(flash);
                setTimeout(() => flash.style.opacity = 0, 50);
                setTimeout(() => flash.remove(), 250);

                if (!mat.userData.filled) {
                    mat.userData.filled = true;
                    capturedCount++;
                    trackerStatus.innerText = `Captured ${capturedCount}/6`;
                    if (capturedCount >= 1) {
                        btnFinish.classList.remove('hidden');
                    }
                }
            }
        }

        function finishAndSave() {
            if(!confirm("Finish and view sphere?")) return;
            
            // Disable tracking
            isViewerMode = true;
            trackerStatus.innerText = "Processing...";
            
            // 1. Generate Equirectangular Image
            // We hide the mesh temporarily to render the SCENE (which is just the box)
            // But actually we want to render the BOX.
            // Setup CubeCamera
            const cubeTarget = new THREE.WebGLCubeRenderTarget(1024);
            const cubeCam = new THREE.CubeCamera(0.1, 100, cubeTarget);
            scene.add(cubeCam);
            
            // Ensure mesh is visible and solid
            cubeMesh.scale.set(1, 1, 1); // Reset scale for external viewing capture
            // We need to render FROM THE CENTER, looking at the box faces.
            // The box faces are at distances.
            
            // Actually, simplest way: Just use the materials we have.
            // But we need to stitch them. 
            // Let's use the shader approach.
            
            // Render the INSIDE of the box to the CubeCamera
            cubeMesh.scale.set(-1, 1, 1); // Ensure it's inside-out
            cubeCam.update(renderer, scene);
            
            // Shader to unwrap
            const equiMat = new THREE.ShaderMaterial({
                uniforms: { map: { value: cubeTarget.texture } },
                vertexShader: `
                    varying vec2 vUv;
                    void main() { vUv = uv; gl_Position = vec4(position, 1.0); }
                `,
                fragmentShader: `
                    uniform samplerCube map;
                    varying vec2 vUv;
                    const float PI = 3.14159265359;
                    void main() {
                        vec2 uv = vUv;
                        float longitude = uv.x * 2.0 * PI - PI;
                        float latitude = uv.y * PI - PI / 2.0;
                        vec3 dir = vec3(
                            -cos(latitude) * sin(longitude),
                            sin(latitude),
                            -cos(latitude) * cos(longitude)
                        );
                        gl_FragColor = textureCube(map, normalize(dir));
                    }
                `,
                side: THREE.DoubleSide
            });
            
            const exportScene = new THREE.Scene();
            const plane = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), equiMat);
            exportScene.add(plane);
            const ortho = new THREE.OrthographicCamera(-1, 1, 1, -1, 0, 1);
            
            renderer.setSize(2048, 1024);
            renderer.render(exportScene, ortho);
            
            // Save to LocalStorage
            try {
                const data = renderer.domElement.toDataURL('image/jpeg', 0.85);
                localStorage.setItem('savedSphere', data);
                enterViewerMode(data);
            } catch(e) {
                alert("Image too large for storage on this device.");
                enterViewerMode(renderer.domElement.toDataURL()); // Try anyway
            }
        }

        function enterViewerMode(dataUrl) {
            // UI Updates
            btnCapture.classList.add('hidden');
            btnFinish.classList.add('hidden');
            btnRestart.classList.remove('hidden');
            document.querySelector('.center-reticle').classList.add('hidden');
            trackerStatus.innerText = "Viewer Mode - Drag to Look";
            video.style.display = 'none'; // Hide webcam
            
            // Reset Scene for viewing
            scene.remove(cubeMesh);
            scene.background = new THREE.Color('#111');
            renderer.setSize(window.innerWidth, window.innerHeight);
            
            // Load Sphere
            const tex = new THREE.TextureLoader().load(dataUrl);
            tex.colorSpace = THREE.SRGBColorSpace;
            const sphGeo = new THREE.SphereGeometry(10, 60, 40);
            const sphMat = new THREE.MeshBasicMaterial({ map: tex, side: THREE.BackSide });
            const sphere = new THREE.Mesh(sphGeo, sphMat);
            sphere.scale.set(-1, 1, 1);
            scene.add(sphere);
            
            // Enable Touch Controls
            camera.position.set(0,0,0.1);
            camera.rotation.set(0,0,0);
            const controls = new OrbitControls(camera, renderer.domElement);
            controls.enableZoom = false;
            controls.rotateSpeed = -0.5;
            
            // Stop OpenCV
            isTracking = false;
            cap.delete(); p0.delete(); p1.delete();
            
            // Animation Loop handles the rest
        }

        function animate() {
            requestAnimationFrame(animate);
            processTracking();
            renderer.render(scene, camera);
        }

    </script>
</body>
</html>
