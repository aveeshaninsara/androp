<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Immersive Globe Hand Tracker</title>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            background-color: #000;
            font-family: 'Courier New', Courier, monospace;
        }

        /* The 3D Canvas */
        #canvas-container {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            z-index: 1;
        }

        /* Debug/Status Overlay */
        #ui-layer {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 10;
            color: #0f0;
            pointer-events: none;
            background: rgba(0, 0, 0, 0.5);
            padding: 10px;
            border-radius: 5px;
        }

        /* Crosshair to help user find center */
        #crosshair {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 20px;
            height: 20px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            transform: translate(-50%, -50%);
            z-index: 5;
            pointer-events: none;
        }

        /* Visual representation of the hand center */
        #hand-cursor {
            position: absolute;
            width: 10px;
            height: 10px;
            background-color: red;
            border-radius: 50%;
            z-index: 6;
            display: none;
            pointer-events: none;
            transform: translate(-50%, -50%);
            box-shadow: 0 0 10px red;
        }

        /* Hide the webcam video element, we only need the data */
        .input_video {
            display: none;
        }

        #loading {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-size: 24px;
            z-index: 20;
        }
    </style>
</head>
<body>

    <div id="loading">Loading AI & 3D Engine...</div>
    
    <div id="ui-layer">
        <div><strong>Status:</strong> <span id="status-text">Waiting for hand...</span></div>
        <div><strong>Action:</strong> <span id="action-text">None</span></div>
        <div style="font-size: 10px; margin-top:5px;">Keep hand visible. Pinch to Zoom In. Point 1 finger to Zoom Out.</div>
    </div>

    <div id="crosshair"></div>
    <div id="hand-cursor"></div>
    <div id="canvas-container"></div>

    <!-- Video element for MediaPipe input -->
    <video class="input_video"></video>

    <!-- Import Three.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    
    <!-- Import MediaPipe Hands -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>

    <script>
        // --- THREE.JS SETUP (The Globe) ---
        const container = document.getElementById('canvas-container');
        const scene = new THREE.Scene();
        
        // Camera setup
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 0, 0.1); // Slightly offset from exact center

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        container.appendChild(renderer.domElement);

        // Create the Sphere (The Globe)
        const geometry = new THREE.SphereGeometry(50, 60, 40);
        
        // Invert the geometry so textures appear on the inside
        geometry.scale(-1, 1, 1);

        // Load a texture (High Res Earth Map)
        const textureLoader = new THREE.TextureLoader();
        // Using a reliable NASA derived texture hosted by ThreeJS examples or similar
        const texture = textureLoader.load('https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Aurora_as_seen_by_IMAGE_satellite_in_UV_flooded.jpg/1280px-Aurora_as_seen_by_IMAGE_satellite_in_UV_flooded.jpg', 
            () => { document.getElementById('loading').style.display = 'none'; },
            undefined,
            (err) => { console.error("Texture error", err); }
        ); 
        // Note: You can replace the URL above with any equirectangular projection map (360 photo)

        const material = new THREE.MeshBasicMaterial({ map: texture });
        const sphere = new THREE.Mesh(geometry, material);
        scene.add(sphere);

        // Resize handler
        window.addEventListener('resize', () => {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        // --- MEDIAPIPE HANDS SETUP ---
        const videoElement = document.getElementsByClassName('input_video')[0];
        const statusText = document.getElementById('status-text');
        const actionText = document.getElementById('action-text');
        const handCursor = document.getElementById('hand-cursor');

        // Configuration for sensitivity
        const DEAD_ZONE = 0.1; // Amount hand needs to move from center to trigger rotation
        const ROTATION_SPEED = 0.03;
        const ZOOM_SPEED = 0.5;
        
        let targetRotationX = 0;
        let targetRotationY = 0;

        function onResults(results) {
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                statusText.innerText = "Hand Detected";
                statusText.style.color = "#0f0";
                
                // We only track the first hand detected
                const landmarks = results.multiHandLandmarks[0];
                
                // 1. Calculate Center of Hand (Wrist is index 0, Middle Finger MCP is 9)
                // Using index 9 (Middle Finger Base) is usually more stable for aiming
                const handX = 1.0 - landmarks[9].x; // Flip X because webcam is mirrored
                const handY = landmarks[9].y;

                // Update Visual Cursor
                handCursor.style.display = "block";
                handCursor.style.left = (handX * 100) + "%";
                handCursor.style.top = (handY * 100) + "%";

                // 2. Logic: Rotation (Movement from Center)
                const centerX = 0.5;
                const centerY = 0.5;
                
                let deltaX = handX - centerX;
                let deltaY = handY - centerY;

                // Apply Deadzone
                if (Math.abs(deltaX) < DEAD_ZONE) deltaX = 0;
                else deltaX = (deltaX > 0 ? deltaX - DEAD_ZONE : deltaX + DEAD_ZONE);

                if (Math.abs(deltaY) < DEAD_ZONE) deltaY = 0;
                else deltaY = (deltaY > 0 ? deltaY - DEAD_ZONE : deltaY + DEAD_ZONE);

                sphere.rotation.y += deltaX * ROTATION_SPEED * 5; // Left/Right
                sphere.rotation.x += deltaY * ROTATION_SPEED * 5; // Up/Down

                // 3. Logic: Gestures (Pinch vs 1 Finger)
                
                // Calculate distance between Index Tip (8) and Thumb Tip (4)
                const thumbTip = landmarks[4];
                const indexTip = landmarks[8];
                const middleTip = landmarks[12];
                const ringTip = landmarks[16];
                const pinkyTip = landmarks[20];
                const wrist = landmarks[0];

                const pinchDist = Math.hypot(indexTip.x - thumbTip.x, indexTip.y - thumbTip.y);
                
                // Check if other fingers are folded (simple check: tip is lower than lower joint? 
                // Easier check: distance from wrist. If Tip is close to wrist, it's folded).
                // Here we use a simplified check for "1 Finger Pointing"
                // Condition: Index extended, Middle/Ring/Pinky folded (close to wrist)
                
                const isPinching = pinchDist < 0.05;
                
                // Simple logic for 1 finger: Index is high (y is low), others are low (y is high) relative to wrist?
                // Actually, let's just use Euclidean distance from wrist to determine folded vs extended
                // This is a rough estimation but works for simple triggers
                const dWristIndex = Math.hypot(indexTip.x - wrist.x, indexTip.y - wrist.y);
                const dWristMiddle = Math.hypot(middleTip.x - wrist.x, middleTip.y - wrist.y);
                
                // "1 Finger" heuristic: Index extended (far from wrist) AND Middle folded (closer to wrist) AND not pinching
                const isOneFinger = (dWristIndex > 0.15) && (dWristMiddle < 0.15) && !isPinching;

                if (isPinching) {
                    actionText.innerText = "PINCH (Zoom In)";
                    actionText.style.color = "cyan";
                    // Zoom In (Decrease FOV)
                    camera.fov = Math.max(10, camera.fov - ZOOM_SPEED);
                    camera.updateProjectionMatrix();
                } else if (isOneFinger) {
                    actionText.innerText = "POINTING (Zoom Out)";
                    actionText.style.color = "yellow";
                    // Zoom Out (Increase FOV)
                    camera.fov = Math.min(120, camera.fov + ZOOM_SPEED);
                    camera.updateProjectionMatrix();
                } else {
                    actionText.innerText = "Neutral";
                    actionText.style.color = "white";
                }

            } else {
                statusText.innerText = "No Hand Detected";
                statusText.style.color = "red";
                actionText.innerText = "-";
                handCursor.style.display = "none";
            }

            renderer.render(scene, camera);
        }

        const hands = new Hands({locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
        }});

        hands.setOptions({
            maxNumHands: 1,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        hands.onResults(onResults);

        const cameraFeed = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({image: videoElement});
            },
            width: 640,
            height: 480
        });

        cameraFeed.start();

    </script>
</body>
</html>
