<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>No-Gyro Camera 360 Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <style>
    html, body {
      margin: 0;
      overflow: hidden;
      background: black;
    }
    video {
      position: fixed;
      bottom: 10px;
      right: 10px;
      width: 140px;
      opacity: 0.2;
      z-index: 10;
      transform: scaleX(-1);
    }
  </style>

  <!-- Three.js -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.155/build/three.min.js"></script>

  <!-- MediaPipe -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</head>

<body>

<video id="video" autoplay muted playsinline></video>

<script>
/* =========================
   THREE.JS 360 SCENE
========================= */

const scene = new THREE.Scene()

const camera = new THREE.PerspectiveCamera(
  75,
  window.innerWidth / window.innerHeight,
  0.1,
  1000
)

const renderer = new THREE.WebGLRenderer({ antialias: true })
renderer.setSize(window.innerWidth, window.innerHeight)
document.body.appendChild(renderer.domElement)

// Sphere
const geometry = new THREE.SphereGeometry(500, 60, 40)
geometry.scale(-1, 1, 1)

// Texture
const texture = new THREE.TextureLoader().load(
  "https://storage.noirlab.edu/media/archives/images/thumb300y/20220407_Pachon_P35mm_SOARG_L_Fulld1-CC.jpg"
)

const material = new THREE.MeshBasicMaterial({ map: texture })
const sphere = new THREE.Mesh(geometry, material)
scene.add(sphere)

camera.rotation.order = "YXZ"

/* =========================
   CAMERA + FACE TRACKING
========================= */

const video = document.getElementById("video")

let yaw = 0
let pitch = 0

let lastX = null
let lastY = null

const faceMesh = new FaceMesh({
  locateFile: file =>
    `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
})

faceMesh.setOptions({
  maxNumFaces: 1,
  refineLandmarks: false,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
})

faceMesh.onResults(results => {
  if (!results.multiFaceLandmarks.length) return

  const lm = results.multiFaceLandmarks[0][1] // nose bridge
  const x = lm.x
  const y = lm.y

  if (lastX !== null) {
    const dx = x - lastX
    const dy = y - lastY

    yaw   -= dx * 2.5
    pitch -= dy * 2.5

    pitch = Math.max(-1.3, Math.min(1.3, pitch))
  }

  lastX = x
  lastY = y
})

const cam = new Camera(video, {
  onFrame: async () => {
    await faceMesh.send({ image: video })
  },
  width: 640,
  height: 480
})

cam.start()

/* =========================
   ANIMATION LOOP
========================= */

function animate() {
  requestAnimationFrame(animate)

  // smooth motion
  camera.rotation.y += (yaw - camera.rotation.y) * 0.08
  camera.rotation.x += (pitch - camera.rotation.x) * 0.08

  renderer.render(scene, camera)
}

animate()

window.addEventListener("resize", () => {
  camera.aspect = window.innerWidth / window.innerHeight
  camera.updateProjectionMatrix()
  renderer.setSize(window.innerWidth, window.innerHeight)
})
</script>

</body>
</html>
